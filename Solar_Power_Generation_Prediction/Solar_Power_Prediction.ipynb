{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries:\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import shapiro, normaltest, kurtosis, skew\n",
    "from statsmodels.stats.diagnostic import lilliefors\n",
    "from statsmodels.api import qqplot\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import clone\n",
    "from sklearn.feature_selection import SelectKBest, SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data:\n",
    "\n",
    "df_raw = pd.read_csv(\"Solar_Power_Plant_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy of the dataset:\n",
    "df = df_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the first 5 rolls:\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information about the dataset:\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing data:\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing Date-Hour(NMT) column type:\n",
    "\n",
    "df['Date-Hour(NMT)'] = pd.to_datetime(df['Date-Hour(NMT)'], format=\"%d.%m.%Y-%H:%M\")\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range of datetime column:\n",
    "\n",
    "print(f\"Range of Datetime column: ({df['Date-Hour(NMT)'].min()}) to ({df['Date-Hour(NMT)'].max()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the Date-Hour(NUMT) as the index:\n",
    "\n",
    "df.set_index(\"Date-Hour(NMT)\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive Statistics analysis:\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's change the type of the numeric variables:\n",
    "\n",
    "df['Sunshine'] = df['Sunshine'].astype(\"int16\")\n",
    "df['RelativeAirHumidity'] = df['RelativeAirHumidity'].astype(\"int16\")\n",
    "df['WindSpeed'] = df['WindSpeed'].astype(\"float32\")\n",
    "df['Radiation'] = df['Radiation'].astype(\"float32\")\n",
    "df['AirTemperature'] = df['AirTemperature'].astype(\"float32\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The memory usage of the dataset reduced from 547.6 to 342.2 KB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information about the dataset:\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how many data points have negative Radiation:\n",
    "\n",
    "df[df[\"Radiation\"] < 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysing average monthly Radiation and Sunshine:\n",
    "\n",
    "df[\"Months\"] = df.index.month_name()\n",
    "df[\"Month_number\"] = df.index.month\n",
    "monthly_rad_sun = df.groupby([\"Month_number\", \"Months\"]).agg({\"Radiation\":\"mean\", \"Sunshine\":\"mean\"}).\\\n",
    "    droplevel(level=\"Month_number\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line plot of the Average monthly Radiation and Sushine\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=1, sharex=True, figsize=(13, 5))\n",
    "fig.suptitle(\"Average monthly Radiation and Sunshine\")\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "sns.lineplot(monthly_rad_sun[\"Radiation\"], ax=ax[0])\n",
    "\n",
    "sns.lineplot(monthly_rad_sun[\"Sunshine\"], ax=ax[1], c=\"r\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Months and Month_number columns:\n",
    "\n",
    "df.drop(columns=[\"Months\", \"Month_number\"], inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions\n",
    "\n",
    "- One year of one-hour mesurements.\n",
    "- As we can see from the statistic summary, there are some negative data points in Radiation column.\n",
    "- Average Monthly Radiation is positive over the year.\n",
    "- The increase of the Radiation and Sunshine between April and August may suggest that this location is situated in the Northern Hemisphere.\n",
    "- Most data in SystemProduction and Sunshine columns may be zero.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Exploratory Data Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1) Distribution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will look at the histogram of all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms:\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3, sharey=False, figsize=(20, 15))\n",
    "fig.suptitle(\"Histograms of the Variables\")\n",
    "\n",
    "sns.histplot(df[\"SystemProduction\"].values, ax=axes[0, 0], kde=True)\n",
    "axes[0, 0].set_title(\"SystemProduction\")\n",
    "\n",
    "sns.histplot(df[\"WindSpeed\"].values, ax=axes[0, 1], kde=True)\n",
    "axes[0, 1].set_title(\"WindSpeed\")\n",
    "\n",
    "sns.histplot(df[\"Sunshine\"].values, ax=axes[0][2], kde=True)\n",
    "axes[0][2].set_title(\"Sunshine\")\n",
    "\n",
    "sns.histplot(df[\"RelativeAirHumidity\"].values, ax=axes[1, 0], kde=True)\n",
    "axes[1, 0].set_title(\"RelativeAirHumidity\")\n",
    "\n",
    "sns.histplot(df[\"Radiation\"].values, ax=axes[1, 1], kde=True, legend=False)\n",
    "axes[1, 1].set_title(\"Radiation\")\n",
    "\n",
    "sns.histplot(df[\"AirTemperature\"].values, ax=axes[1, 2], kde=True)\n",
    "axes[1, 2].set_title(\"AirTemperature\")\n",
    "\n",
    "sns.histplot(df[\"AirPressure\"].values, ax=axes[2, 0], kde=True)\n",
    "axes[2, 0].set_title(\"AirPressure\");\n",
    "\n",
    "axes[2, 1].set_visible(False)\n",
    "axes[2, 2].set_visible(False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the Histograms, we may think that AirPressure column was drew from a normal distribution. Let's look at the boxplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BoxPlots:\n",
    "\n",
    "fig, ax = plt.subplots(3, 3, figsize=(20, 15), sharey=False)\n",
    "fig.suptitle(\"Boxplots\")\n",
    "\n",
    "sns.boxplot(y=df[\"SystemProduction\"].values, ax=ax[0, 0])\n",
    "ax[0, 0].set_xlabel(\"SystemProduction\")\n",
    "\n",
    "sns.boxplot(y=df[\"WindSpeed\"].values, ax=ax[0, 1])\n",
    "ax[0, 1].set_xlabel(\"WindSpeed\")\n",
    "\n",
    "sns.boxplot(y=df[\"Sunshine\"].values, ax=ax[0, 2])\n",
    "ax[0, 2].set_xlabel(\"Sunshine\")\n",
    "\n",
    "sns.boxplot(y=df[\"RelativeAirHumidity\"].values, ax=ax[1, 0])\n",
    "ax[1, 0].set_xlabel(\"RelativeAirHumidity\")\n",
    "\n",
    "sns.boxplot(y=df[\"Radiation\"].values, ax=ax[1, 1])\n",
    "ax[1, 1].set_xlabel(\"Radiation\")\n",
    "\n",
    "sns.boxplot(y=df[\"AirTemperature\"].values, ax=ax[1, 2])\n",
    "ax[1, 2].set_xlabel(\"AirTemperature\")\n",
    "\n",
    "sns.boxplot(y=df[\"AirPressure\"].values, ax=ax[2, 0])\n",
    "ax[2, 0].set_xlabel(\"AirPressure\");\n",
    "\n",
    "ax[2, 1].set_visible(False)\n",
    "ax[2, 2].set_visible(False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2) Normality tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QQ Plots:\n",
    "\n",
    "# Defining subplots:\n",
    "fig, axe = plt.subplots(3, 3, sharey=False, figsize=(20, 20))\n",
    "fig.suptitle(\"Quantile-Quantile Plots\")\n",
    "\n",
    "# Plotting SystemProduction data:\n",
    "qqplot(df[\"SystemProduction\"], ax=axe[0, 0], line=\"s\");\n",
    "axe[0, 0].set_title(\"SystemProduction\")\n",
    "\n",
    "# Plotting WindSpeed data:\n",
    "qqplot(df[\"WindSpeed\"], ax=axe[0, 1], line=\"s\")\n",
    "axe[0, 1].set_title(\"WindSpeed\")\n",
    "\n",
    "# Plotting Sunshine data:\n",
    "qqplot(df[\"Sunshine\"], ax=axe[0, 2], line=\"s\")\n",
    "axe[0, 2].set_title(\"Sunshine\")\n",
    "\n",
    "# Ploting RelativeAirHumidity:\n",
    "qqplot(df[\"RelativeAirHumidity\"], ax=axe[1, 0], line=\"s\")\n",
    "axe[1, 0].set_title(\"RelativeAirHumidity\")\n",
    "\n",
    "# Radiation:\n",
    "qqplot(df[\"Radiation\"], ax=axe[1, 1], line=\"s\")\n",
    "axe[1, 1].set_title(\"Radiation\")\n",
    "\n",
    "# AirTemperature:\n",
    "qqplot(df[\"AirTemperature\"], ax=axe[1, 2], line=\"s\")\n",
    "axe[1, 2].set_title(\"AirTemperature\")\n",
    "\n",
    "# AirPressure\n",
    "qqplot(df[\"AirPressure\"], ax=axe[2, 0], line=\"s\")\n",
    "axe[2, 0].set_title(\"AirPressure\");\n",
    "\n",
    "axe[2, 1].set_visible(False)\n",
    "axe[2, 2].set_visible(False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the qqplot and the Histogram above, it seems tha AirPressure follows a normal distribution. Let's quantify this assumption using statistical tests for normality.\n",
    "\n",
    "- H0: Data was drew from a normal distribution.\n",
    "\n",
    "- H1: Data was not drew from a normal distribution.\n",
    "\n",
    "OBS: Using level of significance of 5% (alpha).\n",
    "\n",
    "OBS2: Shapiro wilk p value is an approximate value due to the size of the sample being more than 5000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that Calculates Shapiro-Wilk, Lilliefors and D'Agostino_K2 tests:\n",
    "\n",
    "def normality_tests(df: any):\n",
    "    tests_names = [\"Shapiro-Wilk\", \"Lilliefors\", \"D'Agostino_K2\"]\n",
    "    extern_index = np.array(sorted(tests_names*2))\n",
    "    intern_index = np.array([\"statistic\", \"p-value\"]*len(tests_names))\n",
    "\n",
    "    mult_index = [\n",
    "        extern_index,\n",
    "        intern_index\n",
    "    ]\n",
    "\n",
    "    results = pd.DataFrame(index=mult_index, columns=df.columns)\n",
    "   \n",
    "    for c in df.columns:\n",
    "        \n",
    "        # First D'Agostino's K-squared test:\n",
    "        k2, k2_p = normaltest(df[c])\n",
    "\n",
    "        # Secondly we will use the Lilliefors test:\n",
    "        lilliefors_result = lilliefors(df[c])\n",
    "        ksstat, lilliefours_p = lilliefors_result\n",
    "\n",
    "        #  We will check the shapiro-Wilk test:\n",
    "        shapiro_result = shapiro(df[c])\n",
    "        shapiro_statistic, shapiro_p = shapiro_result.statistic, shapiro_result.pvalue\n",
    "\n",
    "        results[c] = [k2, k2_p, ksstat, lilliefours_p, shapiro_statistic, shapiro_p]\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Function that calculates kurtosis and skewness of a dataset:\n",
    "\n",
    "def kurtosis_skewness(dataset: any):\n",
    "    index = [\"Kurtosis\", \"Skewness\"]\n",
    "    results = pd.DataFrame(index=index, columns=dataset.columns)\n",
    "    for c in dataset.columns:\n",
    "        kurt = kurtosis(dataset[c])\n",
    "        skewness = skew(dataset[c])\n",
    "        results[c] = [kurt, skewness]\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normality test results:\n",
    "\n",
    "normality_tests(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kurtosis and Skewness:\n",
    "\n",
    "kurtosis_skewness(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution can be considered normal:\n",
    "\n",
    "- Kurtosis between (-1, +1).\n",
    "\n",
    "- Skewness between (-1, +1).\n",
    "\n",
    "- Histogram and QQ Plot.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3) Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix:\n",
    "\n",
    "def heatmap_cor(df):\n",
    "    cor = df.corr()\n",
    "    mascara = np.zeros_like(cor)\n",
    "    mascara[np.triu_indices_from(mascara)] = True\n",
    "    sns.heatmap(cor, mask=mascara, cbar=True, annot=True, cmap=\"crest\")\n",
    "    \n",
    "\n",
    "heatmap_cor(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions\n",
    "\n",
    "- Most of the data in SystemProduction is 0 as we expected since median is zero and the variable can't be negative.\n",
    "\n",
    "- Outliers exist in SystemProduction, AirPressure, RelativeHumidity, Radiation, WindSpeed and Sunshine.\n",
    "\n",
    "- All statistical tests have shown that the AirPressure not follows a normal distribution. However, all these tests are very sensitive when the sample size is large. So we can't rely on them.\n",
    "\n",
    "- Histogram, QQ Plot, Kurtosis and Skewness tell us that AirPressue follows a normal distribution. Therefore, we will assume that AirPressure is normally distributed.\n",
    "\n",
    "- Radiation has the highest positive correlation coefficient associated with the SystemProdution (0.79). It is also hightly correlated with Sushine column.\n",
    "\n",
    "- RelativeAirHumidity has the lowest correlation coefficient associated with the Target. (-0.55)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating variables (features and target)\n",
    "\n",
    "X = df.drop(columns=\"SystemProduction\")\n",
    "y = df[\"SystemProduction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divinding dataset in train and test:\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2) Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to evaluate the best algorithms:\n",
    "\n",
    "def melhor_modelo(X_train, y_train):\n",
    "\n",
    "    seed = 42\n",
    "    cv = 5\n",
    "    score = ['neg_root_mean_squared_error', 'r2']\n",
    "    result_rmse = {}\n",
    "    result_r2 = {}\n",
    "\n",
    "    dicionario = { \n",
    "                \"Lasso\":Lasso(random_state=seed),\n",
    "                \"Ridge\":Ridge(random_state=seed),\n",
    "                \"SVR\":SVR(),\n",
    "                \"RandomForestR\":RandomForestRegressor(random_state=seed),\n",
    "                \"ExtraTreeR\":ExtraTreesRegressor(random_state=seed),\n",
    "                \"XGB\":XGBRegressor(random_state=42),\n",
    "                \"MLP\":MLPRegressor(random_state=42, max_iter=2000)\n",
    "                 }\n",
    "\n",
    "\n",
    "    for name, model in dicionario.items():\n",
    "        k_fold = KFold(n_splits=cv, random_state=seed, shuffle=True)\n",
    "        result = cross_validate(model, X_train, y_train, cv=k_fold, scoring=score)\n",
    "\n",
    "        result_rmse[name] = -result['test_neg_root_mean_squared_error']\n",
    "        result_r2[name] = result['test_r2']\n",
    "        \n",
    "        \n",
    "    result_pd_rmse = pd.DataFrame(data=result_rmse)\n",
    "    result_pd_r2 = pd.DataFrame(data=result_r2)\n",
    "    \n",
    "    return result_pd_rmse, result_pd_r2\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.1) MinMax Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMax Scaler Transformation:\n",
    "\n",
    "min_max = MinMaxScaler()\n",
    "X_train_min_max = min_max.fit_transform(X_train)\n",
    "X_test_min_max = min_max.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model:\n",
    "\n",
    "resultado_rms, resultado_r2 = melhor_modelo(X_train_min_max, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLotting model's performance:\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.title(\"Models's Performance - MinMax Scaler\")\n",
    "sns.boxplot(resultado_rms);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root mean squared error results:\n",
    "\n",
    "resultado_rms.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 results:\n",
    "\n",
    "resultado_r2.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.1) Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Scaler Transformation:\n",
    "\n",
    "std = StandardScaler()\n",
    "X_train_std = std.fit_transform(X_train)\n",
    "X_test_std = std.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model:\n",
    "\n",
    "resultado_rms, resultado_r2 = melhor_modelo(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLotting model's performance:\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.title(\"Models's Performance - Standard Scaler\")\n",
    "sns.boxplot(resultado_rms);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root mean squared error results:\n",
    "\n",
    "resultado_rms.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 results:\n",
    "\n",
    "resultado_r2.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.1) Robust Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robust Scaler Transformation:\n",
    "\n",
    "rob = RobustScaler()\n",
    "X_train_rb = rob.fit_transform(X_train)\n",
    "X_test_rb = rob.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model:\n",
    "\n",
    "resultado_rms, resultado_r2 = melhor_modelo(X_train_rb, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLotting model's performance:\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.title(\"Models's Performance - Robust Scaler\")\n",
    "sns.boxplot(resultado_rms);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root mean squared error results:\n",
    "\n",
    "resultado_rms.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 results:\n",
    "\n",
    "resultado_r2.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions\n",
    "\n",
    "- ExtraTres was the best Algorithm for all of the transformation algorithms.\n",
    "- The Best Trasformation algorithm was Robust Scaler.\n",
    "\n",
    "RMSE:\n",
    "- Average:  775.018174\n",
    "- Standard Deviation: 37.423964\n",
    "\n",
    "R2\n",
    "- Average: 0.734621\n",
    "- Standard Deviation: 0.012831"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class that put together many feature selection techniques:\n",
    "\n",
    "class feature_selector:\n",
    "    seed = 42\n",
    "    def __init__(self, X, y) -> None:\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "    \n",
    "    def  randomforestR_imp(self) -> None:\n",
    "        model = RandomForestRegressor(random_state=feature_selector.seed)\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        series = pd.Series(index=model.feature_names_in_, data=model.feature_importances_).sort_values(ascending=False)\n",
    "\n",
    "        # Plotting RandomForest Regression Importance:\n",
    "        plt.title(\"RandomForest Importance\")\n",
    "        sns.barplot(x=series.values, y=series.index)\n",
    "        \n",
    "\n",
    "    def xgbR_imp(self) -> None:\n",
    "        model = XGBRegressor(random_state=feature_selector.seed)\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        series = pd.Series(index=model.feature_names_in_, data=model.feature_importances_).sort_values(ascending=False)\n",
    "\n",
    "        # Plotting XGboost Regression Feature Importance:\n",
    "        plt.title(\"XGBoost Feature Importance\")\n",
    "        sns.barplot(y=series.index, x=series.values)\n",
    "\n",
    "\n",
    "    # Construção de Seletor de variáveis univariavel\n",
    "    def univariate(self, statistic, n, X_test=None) -> None:\n",
    "        selector = SelectKBest(score_func=statistic, k=n)\n",
    "        X_selected = selector.fit_transform(self.X_train)\n",
    "        \n",
    "        if X_test != None:\n",
    "            X_test_new = selector.transform(X_test)\n",
    "            return X_selected, X_test_new\n",
    "\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = feature_selector(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature.randomforestR_imp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature.xgbR_imp()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for fine tuning an arbitrary model:\n",
    "\n",
    "def tuning(X_train, y_train, modelo, params):\n",
    "    \n",
    "    cv = 5\n",
    "    score = \"neg_root_mean_squared_error\"\n",
    "    grid  = GridSearchCV(modelo, cv=cv, param_grid=params, \n",
    "                         scoring=score, \n",
    "                         n_jobs=-1,\n",
    "                         return_train_score=True,\n",
    "                         )\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    best_index = grid.best_index_\n",
    "    result = grid.cv_results_\n",
    "\n",
    "    train_score = -result['mean_train_score'][best_index]\n",
    "    left_out = -result['mean_test_score'][best_index]\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"Train score: {train_score}\")\n",
    "    print(f\"Left out data score: {left_out}\")\n",
    "\n",
    "    return grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypeparameters grid\n",
    "\n",
    "params = {\"n_estimators\":[200, 300, 320],\n",
    "          \"criterion\":[\"squared_error\", \"friedman_mse\", \"absolute_error\", \"poisson\"],\n",
    "          \"max_depth\":[2, 3, 4, 5, 6],\n",
    "          \"max_features\":[0.5, 0.6, 0.8, \"sqrt\"],\n",
    "          \"min_samples_split\":[3, 5, 6, 7]}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1) No Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_tree = ExtraTreesRegressor(random_state=42)\n",
    "best_estimator = tuning(X_train_rb, y_train, extra_tree, params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2) With Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1) No feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = clone(best_estimator)\n",
    "best_model.fit(X_train_rb, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_train_rb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_train = np.sqrt(mean_squared_error(y_pred, y_train))\n",
    "r2_train = r2_score(y_pred, y_train)\n",
    "\n",
    "print(\"Train set:\")\n",
    "print(f\"RMSE: {rms_train}\")\n",
    "print(f\"R2: {r2_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test_rb)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_pred, y_test))\n",
    "r2_test = r2_score(y_pred, y_test)\n",
    "\n",
    "print(\"Test set:\")\n",
    "print(f\"RMSE: {rmse_test}\")\n",
    "print(f\"R2: {r2_test}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2) With Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
